{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78677adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline, AutoTokenizer, TFAutoModelForCausalLM\n",
    "from googleapiclient.discovery import build\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad43bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"./models/emotion_model.h5\")\n",
    "\n",
    "def preprocess_image(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        img = Image.fromarray((image * 255).astype(np.uint8))\n",
    "    else:\n",
    "        img = Image.open(image)\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((64, 64))\n",
    "    img_rgb = Image.new('RGB', img.size)\n",
    "    img_rgb.paste(img)\n",
    "    img_arr = np.array(img_rgb).reshape(1, 64, 64, 3) / 255.0\n",
    "    \n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de00b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "text_generation_model = TFAutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "API_KEY = 'AIzaSyD4-X0747wo4mXqJrxHwWb7mo1Yq3JhUhE'\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e818eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(emotion):\n",
    "    input_text = f\"Generate a song for {emotion} emotion\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "    # Increase the max_length\n",
    "    generated_text = text_generation_model.generate(input_ids, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "    generated_sentence_full = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Trim the sentence to the last period to ensure completeness\n",
    "    generated_sentence_trimmed = generated_sentence_full.rsplit('.', 1)[0] + '.'\n",
    "    \n",
    "    return generated_sentence_trimmed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552d12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harie\\AppData\\Local\\Temp\\ipykernel_14616\\4268840232.py:25: GradioDeprecationWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  iface = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 774ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Local\\Temp\\ipykernel_14616\\4268840232.py\", line 15, in recommend_music_from_image\n",
      "    ).execute()\n",
      "      ^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\_helpers.py\", line 130, in positional_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\http.py\", line 923, in execute\n",
      "    resp, content = _retry_request(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\http.py\", line 222, in _retry_request\n",
      "    raise exception\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\http.py\", line 191, in _retry_request\n",
      "    resp, content = http.request(uri, method, *args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1724, in request\n",
      "    (response, content) = self._request(\n",
      "                          ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1444, in _request\n",
      "    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1366, in _conn_request\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1158, in connect\n",
      "    self.sock = self._context.wrap_socket(sock, server_hostname=self.host)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\ssl.py\", line 1075, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\ssl.py\", line 1346, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'youtube.googleapis.com'. (_ssl.c:1002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Local\\Temp\\ipykernel_14616\\4268840232.py\", line 15, in recommend_music_from_image\n",
      "    ).execute()\n",
      "      ^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\_helpers.py\", line 130, in positional_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\http.py\", line 923, in execute\n",
      "    resp, content = _retry_request(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\http.py\", line 222, in _retry_request\n",
      "    raise exception\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\googleapiclient\\http.py\", line 191, in _retry_request\n",
      "    resp, content = http.request(uri, method, *args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1724, in request\n",
      "    (response, content) = self._request(\n",
      "                          ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1444, in _request\n",
      "    (response, content) = self._conn_request(conn, request_uri, method, body, headers)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1366, in _conn_request\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\harie\\AppData\\Roaming\\Python\\Python311\\site-packages\\httplib2\\__init__.py\", line 1156, in connect\n",
      "    sock.connect((self.host, self.port))\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n"
     ]
    }
   ],
   "source": [
    "def recommend_music_from_image(image):\n",
    "    image_arr = preprocess_image(image)\n",
    "    prediction = model.predict(image_arr)\n",
    "    emotions = [\"angry\", \"contempt\", \"disgust\", \"fear\", \"happiness\", \"neutrality\", \"sadness\", \"surprise\"]\n",
    "    emotion = emotions[np.argmax(prediction)]\n",
    "\n",
    "    gpt_sentence = generate_sentence(emotion)  # Getting the GPT-2 generated sentence\n",
    "    \n",
    "    search_query = gpt_sentence\n",
    "    search_results = youtube.search().list(\n",
    "        q=search_query,\n",
    "        type='video',\n",
    "        part='id',\n",
    "        maxResults=5\n",
    "    ).execute()\n",
    "\n",
    "    video_ids = [item['id']['videoId'] for item in search_results['items']]\n",
    "    video_urls = ['https://www.youtube.com/watch?v=' + video_id for video_id in video_ids]\n",
    "    \n",
    "    formatted_recommendations = [f'<a href=\"{url}\" target=\"_blank\">Video {i+1}</a>' for i, url in enumerate(video_urls)]\n",
    "    recommendations_text = \"<br>\".join(formatted_recommendations)\n",
    "    \n",
    "    return emotion, gpt_sentence, recommendations_text  # Including the GPT-2 sentence in the output\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=recommend_music_from_image,\n",
    "    inputs=\"image\",\n",
    "    outputs=[\"text\", \"text\", \"html\"],  # Added an additional text output for the GPT-2 generated sentence\n",
    "    layout=\"vertical\",\n",
    "    title=\"Music Recommendation Based on Emotion\",\n",
    "    description=\"Upload an image, and we'll predict the emotion, generate a song line, and recommend music for you.\",\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb427ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
